{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1af4fa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "from skimage import morphology \n",
    "from skimage.transform import rotate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c62dead7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['compactness_2',\n",
       " 'asymmetry',\n",
       " 'luminance_average',\n",
       " 'luminance_variance',\n",
       " 'red_average',\n",
       " 'green_average',\n",
       " 'blue_average',\n",
       " 'color_variance']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the main data set\n",
    "features = pd.read_csv(\"../features/feature_set_with_multiple_perimeters.csv\", sep = \";\")\n",
    "data = pd.read_csv(\"../data/ISIC-2017_Training_Part3_GroundTruth.csv\")\n",
    "\n",
    "image_data = pd.merge(features, data, on = \"image_id\")\n",
    "\n",
    "image_data = image_data.drop([\"image_id\", \"seborrheic_keratosis\", \"area\" , \"perimeter_1\", \"perimeter_2\",\n",
    "                             \"perimeter_3\", \"perimeter_4\", \"compactness_1\", \"compactness_3\", \"compactness_4\"], axis = 1)\n",
    "\n",
    "feature_list = image_data.columns.tolist()\n",
    "feature_list.remove('melanoma')\n",
    "\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89fb9bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-76cb1c0248a6>:25: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  X_val2, y_val2 = X_noisy_scaled_df[X_noisy_scaled_df[\"separator\"] > 15][X_noisy_scaled_df[\"separator\"] < 31], y[X_noisy_scaled_df[\"separator\"] > 15][X_noisy_scaled_df[\"separator\"] < 31]\n",
      "<ipython-input-18-76cb1c0248a6>:26: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  X_val3, y_val3 = X_noisy_scaled_df[X_noisy_scaled_df[\"separator\"] > 30][X_noisy_scaled_df[\"separator\"] < 46], y[X_noisy_scaled_df[\"separator\"] > 30][X_noisy_scaled_df[\"separator\"] < 46]\n",
      "<ipython-input-18-76cb1c0248a6>:27: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  X_val4, y_val4 = X_noisy_scaled_df[X_noisy_scaled_df[\"separator\"] > 45][X_noisy_scaled_df[\"separator\"] < 61], y[X_noisy_scaled_df[\"separator\"] > 45][X_noisy_scaled_df[\"separator\"] < 61]\n",
      "<ipython-input-18-76cb1c0248a6>:28: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  X_val5, y_val5 = X_noisy_scaled_df[X_noisy_scaled_df[\"separator\"] > 60][X_noisy_scaled_df[\"separator\"] < 76], y[X_noisy_scaled_df[\"separator\"] > 60][X_noisy_scaled_df[\"separator\"] < 76]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating the data into train and test sets\\n\",\n",
    "\n",
    "df = image_data\n",
    "\n",
    "# Creates a random variable between 1 and 100 to facilitate splitting the data into multiple sets\n",
    "np.random.seed(0)\n",
    "separator = np.random.randint(1, 101, size = (df.shape[0], 1))\n",
    "\n",
    "# Creates 20 random noise variable to avoid overfitting\n",
    "noise = pd.DataFrame(data = np.random.RandomState(23).uniform(0, 0.1, size = (df.shape[0], 20)), columns = [i for i in range(20)])\n",
    "\n",
    "X = df[feature_list]\n",
    "X_noisy = pd.merge(X, noise, left_index = True, right_index = True)\n",
    "\n",
    "X_scaled = StandardScaler().fit_transform(X.values)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)\n",
    "X_noisy_scaled = StandardScaler().fit_transform(X_noisy.values)\n",
    "X_noisy_scaled_df = pd.DataFrame(X_noisy_scaled, index=X_noisy.index, columns=X_noisy.columns)\n",
    "X_noisy_scaled_df[\"separator\"] = separator\n",
    "y = df['melanoma']\n",
    "\n",
    "\n",
    "#Separating the dataset into 5 different validation sets and 1 test set\n",
    "X_val1, y_val1 = X_noisy_scaled_df[X_noisy_scaled_df[\"separator\"] < 16], y[X_noisy_scaled_df[\"separator\"] < 16]\n",
    "X_val2, y_val2 = X_noisy_scaled_df[X_noisy_scaled_df[\"separator\"] > 15][X_noisy_scaled_df[\"separator\"] < 31], y[X_noisy_scaled_df[\"separator\"] > 15][X_noisy_scaled_df[\"separator\"] < 31]\n",
    "X_val3, y_val3 = X_noisy_scaled_df[X_noisy_scaled_df[\"separator\"] > 30][X_noisy_scaled_df[\"separator\"] < 46], y[X_noisy_scaled_df[\"separator\"] > 30][X_noisy_scaled_df[\"separator\"] < 46]\n",
    "X_val4, y_val4 = X_noisy_scaled_df[X_noisy_scaled_df[\"separator\"] > 45][X_noisy_scaled_df[\"separator\"] < 61], y[X_noisy_scaled_df[\"separator\"] > 45][X_noisy_scaled_df[\"separator\"] < 61]\n",
    "X_val5, y_val5 = X_noisy_scaled_df[X_noisy_scaled_df[\"separator\"] > 60][X_noisy_scaled_df[\"separator\"] < 76], y[X_noisy_scaled_df[\"separator\"] > 60][X_noisy_scaled_df[\"separator\"] < 76]\n",
    "X_test, y_test= X_noisy_scaled_df[X_noisy_scaled_df[\"separator\"] > 75], y[X_noisy_scaled_df[\"separator\"] > 75]\n",
    "\n",
    "validation_sets = [(X_val1, y_val1), (X_val2, y_val2), (X_val3, y_val3), (X_val4, y_val4), (X_val5, y_val5)]\n",
    "\n",
    "#Creating the training sets from the validation sets\n",
    "X_train1 = pd.concat([X_val2, X_val3, X_val4, X_val5])\n",
    "X_train2 = pd.concat([X_val1, X_val3, X_val4, X_val5])\n",
    "X_train3 = pd.concat([X_val1, X_val2, X_val4, X_val5])\n",
    "X_train4 = pd.concat([X_val1, X_val2, X_val3, X_val5])\n",
    "X_train5 = pd.concat([X_val1, X_val2, X_val3, X_val4])\n",
    "\n",
    "y_train1 = pd.concat([y_val2, y_val3, y_val4, y_val5])\n",
    "y_train2 = pd.concat([y_val1, y_val3, y_val4, y_val5])\n",
    "y_train3 = pd.concat([y_val1, y_val2, y_val4, y_val5])\n",
    "y_train4 = pd.concat([y_val1, y_val2, y_val3, y_val5])\n",
    "y_train5 = pd.concat([y_val1, y_val2, y_val3, y_val4])\n",
    "\n",
    "training_sets = [(X_train1, y_train1), (X_train2, y_train2), (X_train3, y_train3), (X_train4, y_train4), (X_train5, y_train5)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "297889b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy score</th>\n",
       "      <th>Roc Auc score</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN_1</td>\n",
       "      <td>0.6928</td>\n",
       "      <td>0.49407</td>\n",
       "      <td>0.16718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN_3</td>\n",
       "      <td>0.75585</td>\n",
       "      <td>0.50516</td>\n",
       "      <td>0.12797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN_5</td>\n",
       "      <td>0.77727</td>\n",
       "      <td>0.49677</td>\n",
       "      <td>0.05784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN_10</td>\n",
       "      <td>0.80475</td>\n",
       "      <td>0.50013</td>\n",
       "      <td>0.01301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN_50</td>\n",
       "      <td>0.80886</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tree</td>\n",
       "      <td>0.68125</td>\n",
       "      <td>0.50982</td>\n",
       "      <td>0.21503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.7043</td>\n",
       "      <td>0.49482</td>\n",
       "      <td>0.15955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier Accuracy score Roc Auc score F1 score\n",
       "0      KNN_1         0.6928       0.49407  0.16718\n",
       "1      KNN_3        0.75585       0.50516  0.12797\n",
       "2      KNN_5        0.77727       0.49677  0.05784\n",
       "3     KNN_10        0.80475       0.50013  0.01301\n",
       "4     KNN_50        0.80886           0.5      0.0\n",
       "5       Tree        0.68125       0.50982  0.21503\n",
       "6   Gaussian         0.7043       0.49482  0.15955"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the classifiers\n",
    "\n",
    "classifiers_name = [\"KNN_1\", \"KNN_3\", \"KNN_5\", \"KNN_10\", \"KNN_50\", \"Tree\", \"Gaussian\"]\n",
    "classifiers = []\n",
    "classifiers.append(KNeighborsClassifier(n_neighbors = 1))\n",
    "classifiers.append(KNeighborsClassifier(n_neighbors = 3))\n",
    "classifiers.append(KNeighborsClassifier(n_neighbors = 5))\n",
    "classifiers.append(KNeighborsClassifier(n_neighbors = 10))\n",
    "classifiers.append(KNeighborsClassifier(n_neighbors = 50))\n",
    "classifiers.append(DecisionTreeClassifier())\n",
    "classifiers.append(GaussianProcessClassifier())\n",
    "\n",
    "accuracy_scores = []\n",
    "auc_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "\n",
    "# Calculating the scores for each classifier for each training set\n",
    "for i in range(len(training_sets)):\n",
    "    trained_classifiers = [classifier.fit(training_sets[i][0], training_sets[i][1]) for classifier in classifiers]\n",
    "    predictions = [trained.predict(validation_sets[i][0]) for trained in trained_classifiers]\n",
    "    accuracy_scores.append([accuracy_score(validation_sets[i][1], prediction) for prediction in predictions])\n",
    "    auc_scores.append([roc_auc_score(validation_sets[i][1], prediction) for prediction in predictions])\n",
    "    f1_scores.append([f1_score(validation_sets[i][1], prediction) for prediction in predictions])\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "accuracy_scores_avg = []\n",
    "auc_scores_avg = []\n",
    "f1_scores_avg = []\n",
    "\n",
    "# Calculating the average score for each classifier\n",
    "for i in range(len(classifiers)):\n",
    "    accuracy_scores_avg.append(np.mean([accuracy_scores[j][i] for j in range(len(training_sets))]))\n",
    "    auc_scores_avg.append(np.mean([auc_scores[j][i] for j in range(len(training_sets))]))\n",
    "    f1_scores_avg.append(np.mean([f1_scores[j][i] for j in range(len(training_sets))]))\n",
    "\n",
    "\n",
    "columns = [\"Classifier\", \"Accuracy score\", \"Roc Auc score\", \"F1 score\"]\n",
    "data = np.array([classifiers_name, np.round(accuracy_scores_avg, decimals = 5), \n",
    "                 np.round(auc_scores_avg, decimals = 5), np.round(f1_scores_avg, decimals = 5)]).T\n",
    "Classifier_evaluation = pd.DataFrame(data = data, columns = columns)\n",
    "Classifier_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6165bb5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baab342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the features\n",
    "predictions = [trained.predict(X_val) for trained in trained_classifiers]\n",
    "\n",
    "accuracy_scores = [accuracy_score(y_val, prediction) for prediction in predictions]\n",
    "auc_scores = [roc_auc_score(y_val, prediction) for prediction in predictions]\n",
    "f1_scores = [f1_score(y_val, prediction) for prediction in predictions]\n",
    "\n",
    "columns = [\"Classifier\", \"Accuracy score\", \"Roc Auc score\", \"F1 score\"]\n",
    "data = np.array([classifiers_name, np.round(accuracy_scores, decimals = 5), \n",
    "                 np.round(auc_scores, decimals = 5), np.round(f1_scores, decimals = 5)]).T\\\n",
    "Classifier_evaluation = pd.DataFrame(data = data, columns = columns)\n",
    "Classifier_evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
